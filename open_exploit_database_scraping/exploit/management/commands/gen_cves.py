from open_exploit_database_scraping.utils.tor_requests import RequestsTor
from open_exploit_database_scraping.exploit.models import Exploit
from django.core.management.base import BaseCommand
from scrapy.crawler import CrawlerProcess
from scrapy import Selector
import requests
import environ
import socket
import csv

env = environ.Env()

class Command(BaseCommand):
    help = "Will go through existing CXSecurity and ExploitDB exploit entries and generate the source url for each entry."

    def add_arguments(self, parser):
        # Add run flags for the two sources that can have their source urls generated from existing entries.
        parser.add_argument("-e", "--exploitdb", action="store_true", help="A no-run flag for ExploitDB source CVE ID generating.")
        parser.add_argument("-c", "--cxsecurity", action="store_true", help="A no-run flag for CXSecurity source CVE ID generating.")

    def handle(self, *args, **kwargs):
        if(kwargs["exploitdb"] and kwargs["cxsecurity"]):
            print("\n[WARNING] Both sources were flagged for no run.")
            return
        # Set up tor request
        tor_service_ip = socket.gethostbyname(env.str('TOR_HOST', default='tor'))
        tor_request = RequestsTor(tor_ports=(9050,), tor_cport=9051, host=tor_service_ip, autochange_id=5, password=env.str('TOR_CONTROLLER_PASSWORD', default='debug'))
        # Entries updated counter
        n_updated = 0

        if kwargs["exploitdb"] is not True:
            exp_updated = 0
            # Download csv.
            exploits_csv = requests.get("https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv")
            csv_content = exploits_csv.content.decode("utf-8")
            csv_reader = csv.DictReader(csv_content.splitlines(), delimiter=',')
            # For each row check the id against the exploits database name (remove file extention) (use .exists())
            for row in csv_reader:
                # Recreate the exploit's name as it would be in the database
                name = row["file"].split('/')[-1] # Essentially is just the exploits id with a file extension.
                # If we have a matching entry, update the entry with its CVE ID
                if Exploit.objects.filter(source="ExploitDB", name=name).exists():
                    # There should only be one entry.
                    exploit = Exploit.objects.filter(source="ExploitDB", name=name).get()
                    # Get the CVE ID(s)
                    cve_id =[]
                    codes = row["codes"].split(';') # The entries are seperated by a ';'
                    for code in codes:
                        if "CVE" in code:
                            cve_id.append(code)
                    # Combine the entries into a comma seperated string.
                    cve_id = ", ".join(cve_id)
                    # Set the cve id in the model and save the change
                    exploit.cve_id = cve_id
                    exploit.save()
                    n_updated += 1
                    exp_updated += 1
                    if exp_updated % 1000 == 0:
                        print(f"\n[INFO]{exp_updated} ExploitDB entries updated.")

        if kwargs["cxsecurity"] is not True:
            cx_updated = 0
            for exploit in Exploit.objects.filter(source="CXSecurity"):
                # Grab the exploit's source URL
                if exploit.source_url and exploit.cve_id is None:
                    # Init CVE ID
                    cve_id = []
                    source_url = exploit.source_url
                    # Use tor to download the source url page.
                    response = tor_request.get(source_url)
                    # Bring in Scrapy's Selector so that we can find the CVE ID using xpath.
                    html_selector = Selector(response=response)
                    # The following xpath gets all of the CVE(s) for an exploit and the CWE
                    # so we will need to filter for only the CVE(s).
                    selected = html_selector.xpath("//div[@class='col-xs-6 col-md-3']/div[@class='well well-sm']/b/a/text()").getall()
                    # Check what we got from the xpath query.
                    for ele in selected:
                        # If it is an CVE, add it to the list.
                        if "CVE" in ele:
                            cve_id.append(ele)
                    # Combine all of the CVE entries into a comma seperated list.
                    cve_id = ", ".join(cve_id)
                    # Set and save it to the the exploit model.
                    exploit.cve_id = cve_id
                    exploit.save()
                    # Keep track of how mant entries we have updated.
                    n_updated += 1
                    cx_updated += 1
                    if cx_updated % 1000 == 0:
                        print(f"\n[INFO]{cx_updated} CXSecurity entries updated.")
                else:
                    # Exploit does not have a source URL, we cannot get CVE ID.
                    continue

        print(f"\n[INFO] {n_updated} exploits were updated with a CVE ID.")