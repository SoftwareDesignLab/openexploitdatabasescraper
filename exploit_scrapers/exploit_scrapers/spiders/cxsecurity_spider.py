from open_exploit_database_scraping.exploit.models import Exploit
import scrapy
import requests
from pathlib import Path
from time import sleep


class CXSecuritySpider(scrapy.Spider):
    name = "cxsecurity"
    start_urls = ["https://cxsecurity.com/exploit/"]
    page = 1
    PAGES = 2#84
    total = 0

    def parse(self, response):
        # Get all links that go to an exploit from the page.
        exploit_links = response.xpath('//div[@class="col-md-7"]/h6/a/@href').getall()
        self.page += 1
        self.total += len(exploit_links)
        print("\n[DEBUG]", response.url, self.total, exploit_links[0], exploit_links[-1])
        # Download the raw version of the exploit example. (Without employing another scraper)
        raw = requests.get(self.get_raw(exploit_links[0])) # For now only scrape the first raw example of each page.
        # Save the response as an html file as this website does not inluce the file extension.
        exploit_file = exploit_links[0].split('/')[-1] + ".html"
        filename = f"exploits/" + exploit_file
        Path(filename).write_bytes(raw.content)
        # Sleep to deter detection.
        sleep(0.5)
        if self.page <= self.PAGES:
            yield scrapy.Request(url=self.start_urls[0] + str(self.page))

    def get_raw(self, url):
        """Helper funciton to get the url of the raw example exploit file."""
        # The raw version of the file is just the same URL with 'issue' replaced with 'ascii'
        # Example: https://cxsecurity.com/issue/WLB-2023060015 -> https://cxsecurity.com/ascii/WLB-2023060015
        # So all we have to do is replace 'issue' with 'ascii'. Python make this very easy.
        return url.replace("issue", "ascii")