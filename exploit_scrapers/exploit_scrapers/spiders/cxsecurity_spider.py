from open_exploit_database_scraping.exploit.models import Exploit
import scrapy
from time import sleep


class CXSecuritySpider(scrapy.Spider):
    name = "cxsecurity"
    start_urls = ["https://cxsecurity.com/exploit/"]
    page = 1
    PAGES = 2#84
    total = 0

    def parse(self, response):
        exploit_links = response.xpath('//div[@class="col-md-7"]/h6/a/@href').getall()
        self.page += 1
        self.total += len(exploit_links)
        print("\n[DEBUG]", response.url, self.total, exploit_links[0], exploit_links[-1])
        sleep(0.5)
        if self.page <= self.PAGES:
            yield scrapy.Request(url=self.start_urls[0] + str(self.page))