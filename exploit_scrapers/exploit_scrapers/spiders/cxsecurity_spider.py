import scrapy
import requests
from pathlib import Path
from time import sleep
from exploit_scrapers.exploit_scrapers.utils import save_exploit


class CXSecuritySpider(scrapy.Spider):
    name = "cxsecurity"
    start_urls = ["https://cxsecurity.com/exploit/"]
    page = 1
    # NOTE: Currently handicapped to two pages, original value was 84.
    # However, on that note. After the initial scraping of the website 
    # the scraper would only need to scrape for new exploits. As in
    # we would only need to check the first few pages.
    PAGES = 2#84
    total = 0

    def parse(self, response):
        # Get all links that go to an exploit from the page.
        exploit_links = response.xpath('//div[@class="col-md-7"]/h6/a/@href').getall()
        # Can also grab other attributes, but will keep them commented out for now
        #titles = response.xpath('//div[@class="col-md-7"]/h6/a/@title').getall()
        #authors = response.xpath('//div[@class="col-md-5"]/h6/span/a/text()').getall()
        self.page += 1
        self.total += len(exploit_links)
        print("\n[DEBUG]", response.url, self.total, exploit_links[0], exploit_links[-1])
        # Download the raw version of the exploit example. (Without employing another scraper)
        raw = self.get_raw(exploit_links[0]) # For now only scrape the first raw example of each page.
        # Save the scraped info into a django model.
        exploit_name = exploit_links[0].split('/')[-1]
        if raw is not None:
            save_exploit(name=exploit_name, is_repo=False, file_name=exploit_name + ".txt", file_content=raw)
        else:
            save_exploit(name=exploit_name, is_repo=False)

        # Save the response as an txt file as this website does not inluce the file extension.
        #exploit_file = exploit_links[0].split('/')[-1] + ".txt"
        #filename = f"exploits/" + exploit_file
        #Path(filename).write_text(raw)

        # Sleep to deter detection.
        sleep(0.5)
        if self.page <= self.PAGES:
            yield scrapy.Request(url=self.start_urls[0] + str(self.page))

    def get_raw(self, url):
        """Helper function to get the exmaple exploit code."""
        # The raw version of the file is just the same URL with 'issue' replaced with 'ascii'
        # Example: https://cxsecurity.com/issue/WLB-2023060015 -> https://cxsecurity.com/ascii/WLB-2023060015
        # So replace 'issue' with 'ascii'. Python make this very easy.
        response = requests.get(url.replace("issue", "ascii"))
        # Unfortunately, CXSecurity's 'raw' files are in html and not exactly raw.
        # So we bring in a scrapy selector to get the example code within the html.
        html_selector = scrapy.Selector(response=response)
        # Now we will use the selector to get the code within the html document.
        return html_selector.xpath("//body/pre//text()").get()