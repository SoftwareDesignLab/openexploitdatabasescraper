from open_exploit_database_scraping.utils.tor_requests import RequestsTor
from exploit_scrapers.exploit_scrapers.utils import save_exploit
from datetime import datetime
from time import sleep
import requests
import environ
import scrapy
import socket
import csv
import sys
import re

env = environ.Env()

class ReadMeSpider(scrapy.Spider):
    name = "readme"
    start_urls = ["https://raw.githubusercontent.com/nomi-sec/PoC-in-GitHub/master/README.md"]
    tor_request = None
    total = 0

    def __init__(self, update):
        tor_service_ip = socket.gethostbyname(env.str('TOR_HOST', default='tor'))
        self.tor_request = RequestsTor(tor_ports=(9050,), tor_cport=9051, host=tor_service_ip, autochange_id=5, password=env.str('TOR_CONTROLLER_PASSWORD', default='debug'))

    def parse(self, response):
        
        for line in response.text.split('\n'):

            # parse file for CVE
            if line.startswith('###'):
                cve = re.search('CVE-\d*-\d*', line).group()

            # parse file for urls
            if line.startswith('-'):
                link = re.search('\(([^)]+)\)', line).group(1)
                author = link.split('/')[3]
                # Create exploit model here
                zip_content = self.download_zip(link, cve+'_'+author+".zip")
                if zip_content is not None:
                    save_exploit(source="github", name=cve+'_'+author, is_repo=True, author=author, file_name=cve+'_'+author+".zip", file_content=zip_content)
                else:
                    save_exploit(source="github", name=cve+'_'+author, is_repo=True, author=author)
                self.total += 1
                print(f"Total repos scraped: {self.total}\nLast zip file status: {cve+'_'+author}\n")
                if self.total >= 2:
                    sys.exit()

    def download_zip(self, url, filename):
        """
        Helper function that attempts to download the repo's zip file.
        NOTE: This function operates off of the assumption that the main
              branch is named either 'main' or 'master'.
        """
        zip_urls = ("/archive/main.zip", "/archive/master.zip")
        not_found_code = 404
        # Attempt to download the archive file
        for zip_url in zip_urls:
            #response = self.tor_request.get(url + zip_url)
            response = requests.get(url + zip_url)
            sleep(5)
            # Check if the url was not valid
            if response.status_code == not_found_code:
                # Try the other archive url
                continue
            else:
                return response.content
        # If both archive urls fail, return None.
        return None
                